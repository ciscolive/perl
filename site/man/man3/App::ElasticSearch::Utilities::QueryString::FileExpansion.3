.\" Automatically generated by Pod::Man 4.14 (Pod::Simple 3.40)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\" ========================================================================
.\"
.IX Title "App::ElasticSearch::Utilities::QueryString::FileExpansion 3"
.TH App::ElasticSearch::Utilities::QueryString::FileExpansion 3 "2020-09-16" "perl v5.32.0" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
App::ElasticSearch::Utilities::QueryString::FileExpansion \- Build a terms query from unique values in a column of a file
.SH "VERSION"
.IX Header "VERSION"
version 7.8
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.SS "App::ElasticSearch::Utilities::QueryString::FileExpansion"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::FileExpansion"
If the match ends in .dat, .txt, .csv, or .json then we attempt to read a file with that name and \s-1OR\s0 the condition:
.PP
.Vb 5
\&    $ cat test.dat
\&    50  1.2.3.4
\&    40  1.2.3.5
\&    30  1.2.3.6
\&    20  1.2.3.7
.Ve
.PP
Or
.PP
.Vb 5
\&    $ cat test.csv
\&    50,1.2.3.4
\&    40,1.2.3.5
\&    30,1.2.3.6
\&    20,1.2.3.7
.Ve
.PP
Or
.PP
.Vb 5
\&    $ cat test.txt
\&    1.2.3.4
\&    1.2.3.5
\&    1.2.3.6
\&    1.2.3.7
.Ve
.PP
Or
.PP
.Vb 5
\&    $ cat test.json
\&    { "ip": "1.2.3.4" }
\&    { "ip": "1.2.3.5" }
\&    { "ip": "1.2.3.6" }
\&    { "ip": "1.2.3.7" }
.Ve
.PP
We can source that file:
.PP
.Vb 2
\&    src_ip:test.dat      => src_ip:(1.2.3.4 1.2.3.5 1.2.3.6 1.2.3.7)
\&    src_ip:test.json[ip] => src_ip:(1.2.3.4 1.2.3.5 1.2.3.6 1.2.3.7)
.Ve
.PP
This make it simple to use the \-\-data\-file output options and build queries
based off previous queries. For .txt and .dat file, the delimiter for columns
in the file must be either a tab or a null.  For files ending in
\&.csv, Text::CSV_XS is used to accurate parsing of the file format.  Files
ending in .json are considered to be newline-delimited \s-1JSON.\s0
.PP
You can also specify the column of the data file to use, the default being the last column or (\-1).  Columns are
\&\fBzero-based\fR indexing. This means the first column is index 0, second is 1, ..  The previous example can be rewritten
as:
.PP
.Vb 1
\&    src_ip:test.dat[1]
.Ve
.PP
or:
    src_ip:test.dat[\-1]
.PP
For newline delimited \s-1JSON\s0 files, you need to specify the key path you want to extract from the file.  If we have a
\&\s-1JSON\s0 source file with:
.PP
.Vb 3
\&    { "first": { "second": { "third": [ "bob", "alice" ] } } }
\&    { "first": { "second": { "third": "ginger" } } }
\&    { "first": { "second": { "nope":  "fred" } } }
.Ve
.PP
We could search using:
.PP
.Vb 1
\&    actor:test.json[first.second.third]
.Ve
.PP
Which would expand to:
.PP
.Vb 1
\&    { "terms": { "actor": [ "alice", "bob", "ginger" ] } }
.Ve
.PP
This option will iterate through the whole file and unique the elements of the list.  They will then be transformed into
an appropriate terms query <http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-terms-query.html>.
.SH "AUTHOR"
.IX Header "AUTHOR"
Brad Lhotsky <brad@divisionbyzero.net>
.SH "COPYRIGHT AND LICENSE"
.IX Header "COPYRIGHT AND LICENSE"
This software is Copyright (c) 2020 by Brad Lhotsky.
.PP
This is free software, licensed under:
.PP
.Vb 1
\&  The (three\-clause) BSD License
.Ve
