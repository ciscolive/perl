.\" Automatically generated by Pod::Man 4.14 (Pod::Simple 3.40)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "Marpa::R2::Semantics::Rank 3"
.TH Marpa::R2::Semantics::Rank 3 "2020-07-11" "perl v5.32.0" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
Marpa::R2::Semantics::Rank \- How ranks are computed
.SH "Synopsis"
.IX Header "Synopsis"
.Vb 3
\&    my $source = <<\*(AqEND_OF_SOURCE\*(Aq;
\&      :discard ~ ws; ws ~ [\es]+
\&      :default ::= action => ::array
\&
\&      Top ::= List action => main::group
\&      List ::= Item3 rank => 3
\&      List ::= Item2 rank => 2
\&      List ::= Item1 rank => 1
\&      List ::= List Item3 rank => 3
\&      List ::= List Item2 rank => 2
\&      List ::= List Item1 rank => 1
\&      Item3 ::= VAR \*(Aq=\*(Aq VAR action => main::concat
\&      Item2 ::= VAR \*(Aq=\*(Aq     action => main::concat
\&      Item1 ::= VAR         action => main::concat
\&      VAR ~ [\ew]+
\&
\&    END_OF_SOURCE
\&
\&    my @tests = (
\&        [ \*(Aqa\*(Aq,                 \*(Aq(a)\*(Aq, ],
\&        [ \*(Aqa = b\*(Aq,             \*(Aq(a=b)\*(Aq, ],
\&        [ \*(Aqa = b = c\*(Aq,         \*(Aq(a=)(b=c)\*(Aq, ],
\&        [ \*(Aqa = b = c = d\*(Aq,     \*(Aq(a=)(b=)(c=d)\*(Aq, ],
\&        [ \*(Aqa = b c = d\*(Aq,       \*(Aq(a=b)(c=d)\*(Aq ],
\&        [ \*(Aqa = b c = d e =\*(Aq,   \*(Aq(a=b)(c=d)(e=)\*(Aq ],
\&        [ \*(Aqa = b c = d e\*(Aq,     \*(Aq(a=b)(c=d)(e)\*(Aq ],
\&        [ \*(Aqa = b c = d e = f\*(Aq, \*(Aq(a=b)(c=d)(e=f)\*(Aq ],
\&    );
\&
\&    my $grammar = Marpa::R2::Scanless::G\->new( { source => \e$source } );
\&    for my $test (@tests) {
\&        my ( $input, $output ) = @{$test};
\&        my $recce = Marpa::R2::Scanless::R\->new(
\&            {
\&                grammar        => $grammar,
\&                ranking_method => \*(Aqhigh_rule_only\*(Aq
\&            }
\&        );
\&        $recce\->read( \e$input );
\&        my $value_ref = $recce\->value();
\&        if ( not defined $value_ref ) {
\&            die \*(AqNo parse\*(Aq;
\&        }
\&        push @results, ${$value_ref};
\&    }
.Ve
.PP
.Vb 2
\&    sub flatten {
\&        my ($array) = @_;
\&
\&        # say STDERR \*(Aqflatten arg: \*(Aq, Data::Dumper::Dumper($array);
\&        my $ref = ref $array;
\&        return [$array] if $ref ne \*(AqARRAY\*(Aq;
\&        my @flat = ();
\&      ELEMENT: for my $element ( @{$array} ) {
\&            my $ref = ref $element;
\&            if ( $ref ne \*(AqARRAY\*(Aq ) {
\&                push @flat, $element;
\&                next ELEMENT;
\&            }
\&            my $flat_piece = flatten($element);
\&            push @flat, @{$flat_piece};
\&        }
\&        return \e@flat;
\&    }
\&
\&    sub concat {
\&        my ( $pp, @args ) = @_;
\&
\&        # say STDERR \*(Aqconcat: \*(Aq, Data::Dumper::Dumper(\e@args);
\&        my $flat = flatten( \e@args );
\&        return join \*(Aq\*(Aq, @{$flat};
\&    }
\&
\&    sub group {
\&        my ( $pp, @args ) = @_;
\&
\&        # say STDERR \*(Aqcomma_sep args: \*(Aq, Data::Dumper::Dumper(\e@args);
\&        my $flat = flatten( \e@args );
\&        return join \*(Aq\*(Aq, map { +\*(Aq(\*(Aq . $_ . \*(Aq)\*(Aq; } @{$flat};
\&    }
.Ve
.SH "Description"
.IX Header "Description"
This document describes rule ranking.
Rule ranking plays a role in parse ordering,
which is described in a separate
document.
.SH "Lexeme locations and fenceposts"
.IX Header "Lexeme locations and fenceposts"
The lexeme locations are an ordered set
of sets of lexemes.
Numbering of lexeme locations is 0\-based.
.PP
It is also useful to use an idea of locations
\&\fBbetween\fR lexeme locations \*(--
This is the classic \*(L"fencepost\*(R" issue \*(-- sometimes
you want to count sections of fence,
and in other cases it is more convenient to count
fenceposts.
.PP
Let the lexeme locations be from 0 to \f(CW\*(C`N\*(C'\fR.
If \f(CW\*(C`I\*(C'\fR is greater than 1 and less than \f(CW\*(C`N\*(C'\fR,
then lexeme fencepost \f(CW\*(C`I\*(C'\fR is before lexeme location \f(CW\*(C`I\*(C'\fR
and after lexeme location \f(CW\*(C`I\-1\*(C'\fR.
lexeme fencepost \f(CW0\fR is before lexeme location 0.
lexeme fencepost \f(CW\*(C`N\*(C'\fR is after lexeme location \f(CW\*(C`N\*(C'\fR
.PP
The above implies that
.IP "\(bu" 4
If there are \f(CW\*(C`N\*(C'\fR lexeme locations,
there are \f(CW\*(C`N+1\*(C'\fR lexeme fenceposts.
.IP "\(bu" 4
lexeme location \f(CW\*(C`I\*(C'\fR is always between
lexeme fencepost \f(CW\*(C`I\*(C'\fR and
lexeme fencepost \f(CW\*(C`I+1\*(C'\fR.
.PP
Lexeme locations and fenceposts are closely related
to G1
locations.
.SH "Dotted Rules"
.IX Header "Dotted Rules"
To understand this document,
it is important to understand what a dotted rule is.
An acquaintance with
dotted rules is also important in understanding
Marpa's progress reports.
Dotted rules
are thoroughly described
in the progress report
documentation.
This section repeats the main ideas
from the perspective of this document.
.PP
Recall that a rule is a \fB\s-1LHS\s0\fR (left hand side)
and a \fB\s-1RHS\s0\fR (right hand side).
The \fB\s-1LHS\s0\fR is always exactly one symbol.
The \fB\s-1RHS\s0\fR is zero or more symbols.
Consider the following example of a rule,
given in the syntax of Marpa's \s-1DSL.\s0
.PP
.Vb 1
\&    S ::= A B C
.Ve
.PP
Dotted rules are used to track the
progress of a parse through a rule.
They consist of a rule and a \fBdot position\fR,
which marks the point in the \s-1RHS\s0 which scanning
has reached.
It is called the \fBdot position\fR because,
traditionally,
the position is represented by a dot.
The symbol before the dot is called
the \fBpredot symbol\fR.
.PP
The following is an example of a dotted rule.
(The dot of a dotted rule is not part of Marpa's \s-1DSL\s0 but,
when it is useful for illustration,
we will use it in the notation in this document.)
.PP
.Vb 1
\&    S ::= A B . C
.Ve
.PP
In this rule, \fBB\fR is the \fBpredot symbol\fR.
.PP
When the dot is after the last symbol of the \s-1RHS,\s0
the dotted rule is called a \fBcompletion\fR.
Here is the completion for the above rule:
.PP
.Vb 1
\&    S ::= A B C .
.Ve
.PP
In this completion example, the symbol \fBC\fR
is the predot symbol.
.PP
When the dot is before the first symbol of the \s-1RHS,\s0
the rule is called a \fBprediction\fR.
Here is the prediction of the rule we've been
using for our examples:
.PP
.Vb 1
\&    S ::= . A B C
.Ve
.PP
In predictions, there is no predot symbol.
.SH "Choicepoints"
.IX Header "Choicepoints"
Informally
a \fBchoicepoint\fR is a place where the parser
can decide among one or more \fBparse choices\fR.
A choicepoint can be thought of either a set
of parse choices,
or as the tuple of the properties which all
the parse choices for the choicepoint
must have in common.
.PP
For a choicepoint to work, all the choices must
have enough in common that each of them
could be replaced with any other.
Thought of as a tuple of properties,
a choicepoint is a triple: \f(CW\*(C`(dp, start, current)\*(C'\fR.
In this triple,
.IP "\(bu" 4
\&\f(CW\*(C`dp\*(C'\fR is a dotted rule.
The predot symbol of \f(CW\*(C`dp\*(C'\fR
is the \fBpredot symbol\fR of the choicepoint \*(--
if \f(CW\*(C`dp\*(C'\fR is a prediction,
there is no predot symbol.
The rule of \f(CW\*(C`dp\*(C'\fR
is the \fBrule\fR of the choicepoint.
The
dot position of \f(CW\*(C`dp\*(C'\fR
is the \fBdot position\fR of the choicepoint.
.IP "\(bu" 4
\&\f(CW\*(C`start\*(C'\fR is the lexeme location where the dotted
rule begins.
\&\f(CW\*(C`start\*(C'\fR is sometimes called the \fBorigin\fR of the
choicepoint.
.IP "\(bu" 4
\&\f(CW\*(C`current\*(C'\fR is the lexeme location corresponding to the dot
in \f(CW\*(C`dp\*(C'\fR.
\&\f(CW\*(C`current\*(C'\fR is sometimes
called the \f(CW\*(C`current location\*(C'\fR of the choicepoint.
.PP
The choicepoint is a prediction choicepoint if
\&\f(CW\*(C`dp\*(C'\fR is a prediction.
The choicepoint is a token choicepoint if
it is not a prediction choicepoint and
the predot symbol of \f(CW\*(C`dp\*(C'\fR is a token symbol.
The choicepoint is a rule choicepoint if
it is not a prediction choicepoint and
the predot symbol of \f(CW\*(C`dp\*(C'\fR is the \s-1LHS\s0 of a rule.
(Token symbols are never the \s-1LHS\s0 of a rule,
and vice versa.)
.SH "Parse choices"
.IX Header "Parse choices"
As mentioned, a choicepoint can be seen as a set
of one or more \fBparse choices\fR.
From the point of view of the individual parse trees,
the traversal is top-down
and left-to-right.
.PP
Often, there is only one parse choice.
When there is only one parse choice,
the choicepoint is said to be \fBtrivial\fR.
Prediction and token choicepoints are always trivial.
If all of the choicepoints of a parse
are trivial,
the parse is unambiguous.
.PP
Every rule choicepoint,
and therefore every non-trivial choicepoint,
has a set of parse choices associated with it.
For a rule choicepoint,
each parse choice is a duple: \f(CW\*(C`(predecessor, cause)\*(C'\fR,
where
\&\f(CW\*(C`cause\*(C'\fR and \f(CW\*(C`predecesor\*(C'\fR are also choicepoints.
The first element of the duple is the \fBpredecessor choicepoint\fR,
or \fBpredecessor\fR,
of the parse choice.
The second element of the duple is the \fBcause choicepoint\fR,
or \fBcause\fR
of the parse choice.
.PP
Let \f(CW\*(C`res\*(C'\fR be a rule choicepoint
and let \f(CW\*(C`(pred, cuz)\*(C'\fR be one of the
parse choices of \f(CW\*(C`res\*(C'\fR.
Then we say that \f(CW\*(C`res\*(C'\fR is the \fBresult\fR
of \f(CW\*(C`cuz\*(C'\fR and \f(CW\*(C`pred\*(C'\fR;
and we say that \f(CW\*(C`cuz\*(C'\fR is one of the \fBcauses\fR
of \f(CW\*(C`res\*(C'\fR.
.PP
The predecessor of a parse choice
represents a portion
of the parse that \*(L"leads up to\*(R" the cause.
The predecessor
of a parse choice plays no role in ranking
decisions,
and this document will mostly ignore predecessors.
.SH "Causes"
.IX Header "Causes"
Since it is a choicepoint, a cause choicepoint
must also be a triple.
Let the result of \f(CW\*(C`cuz\*(C'\fR be
\&\f(CW\*(C`res\*(C'\fR.
Let the triple for for \f(CW\*(C`cuz\*(C'\fR be \f(CW\*(C`(cuz\-dp, cuz\-origin, cuz\-current)\*(C'\fR.
Let the
triple for for \f(CW\*(C`res\*(C'\fR be \f(CW\*(C`(res\-dp, res\-origin, res\-current)\*(C'\fR.
.PP
If \f(CW\*(C`res\*(C'\fR is the result of \f(CW\*(C`cuz\*(C'\fR, then
.IP "\(bu" 4
\&\f(CW\*(C`cuz\-current\*(C'\fR is always the same as
\&\f(CW\*(C`res\-current\*(C'\fR.
In other words,
the current location of \f(CW\*(C`cuz\*(C'\fR
is the same as the current location of \f(CW\*(C`res\*(C'\fR.
.IP "\(bu" 4
\&\f(CW\*(C`cuz\-origin\*(C'\fR is before \f(CW\*(C`res\-current\*(C'\fR.
In other words,
the origin of \f(CW\*(C`cuz\*(C'\fR
is before the current location of \f(CW\*(C`res\*(C'\fR.
.IP "\(bu" 4
\&\f(CW\*(C`cuz\-origin\*(C'\fR
is at or after \f(CW\*(C`res\-origin\*(C'\fR.
In other words,
the origin of \f(CW\*(C`cuz\*(C'\fR
is at or after the origin of \f(CW\*(C`res\*(C'\fR.
While it is not always properly between
\&\f(CW\*(C`res\-origin\*(C'\fR and \f(CW\*(C`res\-current\*(C'\fR,
\&\f(CW\*(C`cuz\-origin\*(C'\fR is always in the range bounded
by
\&\f(CW\*(C`res\-origin\*(C'\fR on one side,
and by \f(CW\*(C`res\-current\*(C'\fR
on the other.
\&\f(CW\*(C`cuz\-origin\*(C'\fR
can therefore be thought of as \*(L"in the middle\*(R"
of the parse choice.
For this reason,
\&\f(CW\*(C`cuz\-origin\*(C'\fR is often called the
\&\fBmiddle location\fR of the parse choice.
.IP "\(bu" 4
The dotted rule of \f(CW\*(C`cuz\*(C'\fR will be a completion.
.IP "\(bu" 4
The \s-1LHS\s0 of the dotted rule of \f(CW\*(C`cuz\*(C'\fR will be
the predot symbol of \f(CW\*(C`res\*(C'\fR.
.PP
Summing up the above,
the causes of a rule choicepoint
vary only by
middle position
and rule \s-1RHS.\s0
The causes of a rule choicepoint
always share the same current lexeme location
and rule \s-1LHS,\s0
and their dotted rules
are always completions.
.SH "Rank is by Cause"
.IX Header "Rank is by Cause"
The rank of a parse choice is that of its cause.
The rank of a cause is the rank of its rule.
Therefore, the rank of a parse choice is the rank
of the rule of its cause.
That last sentence
is the most important sentence of this document,
so we will repeat it:
.PP
.Vb 2
\&    The rank of a parse choice is
\&    the rank of the rule of its cause.
.Ve
.SH "Motivation"
.IX Header "Motivation"
By the definition of the previous section,
the rule of the choicepoint itself plays no
direct role in ranking.
Instead,
the ranking is based on the rules of one
of the choicepoint's
child nodes.
At first,
this may seem unnecessarily roundabout,
and even counter-intuitive,
but on reflection,
it will make sense.
.PP
Ranking cannot be based
directly on the rank of the choicepoint's rule
because every parse choice for that choicepoint shares
the choicepoint's rule.
We have not examined the internal structure of
predecessors, but ranking is not based on them
for the same reason:
the rule of a predecessor is always
the same as the rule of its result choicepoint,
and therefore the rule of its predecessor
is the same for every parse choice of a choicepoint.
.PP
On the other hand,
the causes of parse choices can and often do
differ in their rules.
Therefore ranking is based on the rules of
the causes of a choicepoint.
.PP
Note that ranking is only by \fBdirect\fR causes.
It might reasonably be asked,
why not, at least in the case of a tie,
look at causes of causes.
Or why not resolve ties by looking at causes of
predecessors?
.PP
Marpa's built-in rule ranking
was chosen to be the most powerful system
that could be implemented with effectively
zero cost.
Ranking by direct causes uses only information
that is quickly and directly available,
so that its runtime cost is probably
not measurable.
.PP
Complexity was also an issue.
If indirect causes are taken into account,
we would need to specify which causes,
and under what circumstances they are used.
Only causes of causes?
Or causes of predecessors?
Depth-first, or breadth-first?
Only in case of ties, or using a more complex metric?
To arbitrary depth, or using a traversal that is
cut off at some point?
.PP
Ranking by direct causes only means the answer
to all of these questions is as simple as it can be.
Once we get into analyzing the synopsis grammar in detail,
the importance of simplicity will become clear.
.PP
To be sure,
there are apps
whose requirements justify extra overhand and extra 
complexity.
For these apps,
Marpa's \s-1ASF\s0's
allow full generality in ranking.
.SH "Examples"
.IX Header "Examples"
Our examples in this document will look at
the ranked grammar in the synopsis,
and at minor variations of it.
.SS "Longest highest, version 1"
.IX Subsection "Longest highest, version 1"
We will first consider the example as it
is given in the
synopsis:
.PP
.Vb 2
\&  :discard ~ ws; ws ~ [\es]+
\&  :default ::= action => ::array
\&
\&  Top ::= List action => main::group
\&  List ::= Item3 rank => 3
\&  List ::= Item2 rank => 2
\&  List ::= Item1 rank => 1
\&  List ::= List Item3 rank => 3
\&  List ::= List Item2 rank => 2
\&  List ::= List Item1 rank => 1
\&  Item3 ::= VAR \*(Aq=\*(Aq VAR action => main::concat
\&  Item2 ::= VAR \*(Aq=\*(Aq     action => main::concat
\&  Item1 ::= VAR         action => main::concat
\&  VAR ~ [\ew]+
.Ve
.PP
\fILongest highest ranking\fR
.IX Subsection "Longest highest ranking"
.PP
The \s-1DSL\s0 in the synopsis ranks its items
\&\*(L"longest highest\*(R".
Here \*(L"items\*(R" are represented by the symbols,
\&\f(CW\*(C`<Item3>\*(C'\fR,
\&\f(CW\*(C`<Item2>\*(C'\fR and
\&\f(CW\*(C`<Item1>\*(C'\fR.
The \*(L"longest\*(R" choice is considered to be the one
with the most lexemes.
Working this idea out for this grammar,
we see that the items
should rank,
from highest to lowest:
\&\f(CW\*(C`<Item3>\*(C'\fR,
\&\f(CW\*(C`<Item2>\*(C'\fR and
\&\f(CW\*(C`<Item1>\*(C'\fR.
.PP
\fIThe non-trivial choicepoints\fR
.IX Subsection "The non-trivial choicepoints"
.PP
Several examples and their results are shown
in the synopsis.
If you study the grammar, you will see that
the non-trivial choicepoints
will be for the dotted rules:
.PP
.Vb 4
\&    Top ::= List .
\&    List ::= List . Item3
\&    List ::= List . Item2
\&    List ::= List . Item1
.Ve
.PP
The above are all of the potential
dotted rules for \fBresult\fR choicepoints.
.PP
\fIThe cause choicepoints\fR
.IX Subsection "The cause choicepoints"
.PP
In all of these dotted rules,
the predot symbol is \f(CW\*(C`<List>\*(C'\fR.
Recall that cause choicepoints are always completions.
Since the predot symbol
of all the non-trivial choicepoints
is \f(CW\*(C`<List>\*(C'\fR,
the dotted rule of a cause
of the non-trivial choicepoints
may be any of
.PP
.Vb 6
\&    List ::= Item1 .
\&    List ::= Item2 .
\&    List ::= Item3 .
\&    List ::= List Item1 .
\&    List ::= List Item2 .
\&    List ::= List Item3 .
.Ve
.PP
In fact, if we study the grammar more closely,
we will see that the only possible ambiguity is
in the sequence of items,
and that ambiguities always
take the form "\f(CW\*(C`(v=)(v)\*(C'\fR\*(L" versus
\&\*(R"\f(CW\*(C`(v=v)\*(C'\fR".
Therefore the only causes of non-trivial parse choices are
.PP
.Vb 4
\&    List ::= Item3 .
\&    List ::= Item1 .
\&    List ::= List Item3 .
\&    List ::= List Item1 .
.Ve
.PP
\fIThe first non-trivial choicepoints\fR
.IX Subsection "The first non-trivial choicepoints"
.PP
Further study of the grammar shows that the first non-trivial
choice must be between
two parse choices with
these cause choicepoints:
.PP
.Vb 2
\&    List ::= Item3 .
\&    List ::= Item1 .
.Ve
.PP
The rule
\&\f(CW\*(C`List ::= Item3\*(C'\fR
has rank 3,
and it obviously outranks
the rule
\&\f(CW\*(C`List ::= Item1\*(C'\fR,
which has rank 1.
Our example uses \f(CW\*(C`high_rank_only\*(C'\fR
ranking,
and our example therefore will
leave only this choice:
.PP
.Vb 1
\&    List ::= Item3 .
.Ve
.PP
With only one choice left, the resulting choicepoint
becomes trivial,
and, as defined above, that remaining choice is \*(L"longest\*(R",
and therefore the correct one for the \*(L"longest highest\*(R"
ranking.
.PP
\fIThe second and subsequent non-trivial choicepoints\fR
.IX Subsection "The second and subsequent non-trivial choicepoints"
.PP
We've looked at only the first non-trivial choice
for our example code.
Again examining the grammar, we see that
the second and subsequent non-trivial choices will
all be between
parse choices whose causes have these two dotted
rules:
.PP
.Vb 2
\&    List ::= List Item3 .
\&    List ::= List Item1 .
.Ve
.PP
The rule
\&\f(CW\*(C`List ::= List Item3\*(C'\fR
has rank 3,
and it obviously outranks
the rule
\&\f(CW\*(C`List ::= List Item1\*(C'\fR,
which has rank 1.
Our example uses \f(CW\*(C`high_rank_only\*(C'\fR
ranking,
and our example therefore will
leave only this choice:
.PP
.Vb 1
\&    List ::= List Item3 .
.Ve
.PP
\fIConclusion\fR
.IX Subsection "Conclusion"
.PP
We have now shown that our example will reduce
all choicepoints to a single choice,
one which is consistent with
\&\*(L"longest highest\*(R" ranking.
Since all choicepoints are reduced to a single
choice,
the ranked grammar in unambiguous.
.PP
This analysis made a lot of unstated assumptions.
Below, there is
a \*(L"Proof of correctness\*(R".
It deals with this same example,
but proceeds much more carefully.
.SS "Shortest highest, version 1"
.IX Subsection "Shortest highest, version 1"
Here we see the grammar of the synopsis,
reworked for a \*(L"shortest highest\*(R"
ranking.
\&\*(L"Shortest highest\*(R" is the reverse of
\&\*(L"longest highest\*(R".
.PP
.Vb 2
\&  :discard ~ ws; ws ~ [\es]+
\&  :default ::= action => ::array
\&
\&  Top ::= List action => main::group
\&  List ::= Item3 rank => 1
\&  List ::= Item2 rank => 2
\&  List ::= Item1 rank => 3
\&  List ::= List Item3 rank => 1
\&  List ::= List Item2 rank => 2
\&  List ::= List Item1 rank => 3
\&  Item3 ::= VAR \*(Aq=\*(Aq VAR action => main::concat
\&  Item2 ::= VAR \*(Aq=\*(Aq     action => main::concat
\&  Item1 ::= VAR         action => main::concat
\&  VAR ~ [\ew]+
.Ve
.PP
Here are what the results will look like for
\&\*(L"shortest highest\*(R".
.PP
.Vb 10
\&    my @tests = (
\&        [ \*(Aqa\*(Aq,                 \*(Aq(a)\*(Aq, ],
\&        [ \*(Aqa = b\*(Aq,             \*(Aq(a=)(b)\*(Aq, ],
\&        [ \*(Aqa = b = c\*(Aq,         \*(Aq(a=)(b=)(c)\*(Aq, ],
\&        [ \*(Aqa = b = c = d\*(Aq,     \*(Aq(a=)(b=)(c=)(d)\*(Aq, ],
\&        [ \*(Aqa = b c = d\*(Aq,       \*(Aq(a=)(b)(c=)(d)\*(Aq ],
\&        [ \*(Aqa = b c = d e =\*(Aq,   \*(Aq(a=)(b)(c=)(d)(e=)\*(Aq ],
\&        [ \*(Aqa = b c = d e\*(Aq,     \*(Aq(a=)(b)(c=)(d)(e)\*(Aq ],
\&        [ \*(Aqa = b c = d e = f\*(Aq, \*(Aq(a=)(b)(c=)(d)(e=)(f)\*(Aq ],
\&    );
.Ve
.PP
The reader who wants an example of a ranking scheme
to work out for themselves may find this one suitable.
The reasoning will very similar to that for the
\&\*(L"longest highest\*(R"
example,
just above.
.SS "Longest highest, version 2"
.IX Subsection "Longest highest, version 2"
The previous examples have shown the rule involved
in parse ranking in \*(L"spelled out\*(R" form.
In fact, a more compact form of the grammar can be used,
as shown below for
\&\*(L"longest highest\*(R" ranking.
.PP
.Vb 2
\&  :discard ~ ws; ws ~ [\es]+
\&  :default ::= action => ::array
\&
\&  Top ::= List action => main::group
\&  List ::= Item rank => 1
\&  List ::= List Item rank => 0
\&  Item ::= VAR \*(Aq=\*(Aq VAR rank => 3 action => main::concat
\&  Item ::= VAR \*(Aq=\*(Aq     rank => 2 action => main::concat
\&  Item ::= VAR         rank => 1 action => main::concat
\&  VAR ~ [\ew]+
.Ve
.SS "Shortest highest, version 2"
.IX Subsection "Shortest highest, version 2"
This is the grammar for \*(L"shortest highest\*(R",
in compact form:
.PP
.Vb 2
\&  :discard ~ ws; ws ~ [\es]+
\&  :default ::= action => ::array
\&
\&  Top ::= List action => main::group
\&  List ::= Item rank => 0
\&  List ::= List Item rank => 1
\&  Item ::= VAR \*(Aq=\*(Aq VAR rank => 1 action => main::concat
\&  Item ::= VAR \*(Aq=\*(Aq     rank => 2 action => main::concat
\&  Item ::= VAR         rank => 3 action => main::concat
\&  VAR ~ [\ew]+
.Ve
.PP
Again, the reader looking for simple examples to work
out for themselves may want to rework
the argument given
above for the \*(L"spelled out\*(R"
examples
for the compact examples.
.SH "Alternatives to Ranking"
.IX Header "Alternatives to Ranking"
.SS "Reimplementation as pure \s-1BNF\s0"
.IX Subsection "Reimplementation as pure BNF"
It is generally better, when possible,
to write a language as \s-1BNF,\s0 instead of using ranking.
The advantage of using \s-1BNF\s0 is that you can more readily determine
exactly what language it is that you are parsing:
Ranked grammars make look easier to analyze at first glance,
but the more you look at them the more tricky you
realize they are.
.PP
These \*(L"pure \s-1BNF\*(R"\s0 reimplementations rely on an observation
used in the detailed proof of the ranked \s-1BNF\s0
example:
The parse string becomes easier to analyze
when you see it as a sequence of \*(L"var-bounded\*(R"
substrings,
where \*(L"var-bounded\*(R" means the substring is
delimited by the start of the string,
the end of the string,
or the fencepost between
two \f(CW\*(C`<VAR>\*(C'\fR lexemes.
.PP
\fILongest highest as pure \s-1BNF\s0\fR
.IX Subsection "Longest highest as pure BNF"
.PP
Here is the \*(L"longest highest\*(R" example,
reimplemented as \s-1BNF:\s0
.PP
.Vb 2
\&  :discard ~ ws; ws ~ [\es]+
\&  :default ::= action => ::array
\&
\&  Top            ::= Max_Boundeds action => main::group
\&  Top            ::= Max_Boundeds Unbounded action => main::group
\&  Top            ::= Unbounded action => main::group
\&  Max_Boundeds   ::= Max_Bounded+
\&  Max_Bounded    ::= Eq_Finals Var_Final3
\&  Max_Bounded    ::= Var_Final
\&  Unbounded      ::= Eq_Finals
\&  Eq_Finals      ::= Eq_Final+
\&  Var_Final      ::= Var_Final3 | Var_Final1
\&  Var_Final3     ::= VAR \*(Aq=\*(Aq VAR action => main::concat
\&  Eq_Final       ::= VAR \*(Aq=\*(Aq     action => main::concat
\&  Var_Final1     ::= VAR         action => main::concat
\&  VAR ~ [\ew]+
.Ve
.PP
\fIShortest highest as pure \s-1BNF\s0\fR
.IX Subsection "Shortest highest as pure BNF"
.PP
We can also reimplement the \*(L"shortest highest\*(R"
example as \s-1BNF.\s0
One of the advantages of a \s-1BNF\s0 (re)implementation,
is that it often clarifies the grammar.
For example
in this case, we note that
the \s-1DSL\s0 rule
.PP
.Vb 1
\&  Var_Final3     ::= VAR \*(Aq=\*(Aq VAR action => main::concat
.Ve
.PP
is, in fact, never used.
We therefore omit it:
.PP
.Vb 2
\&  :discard ~ ws; ws ~ [\es]+
\&  :default ::= action => ::array
\&
\&  Top            ::= Max_Boundeds action => main::group
\&  Top            ::= Max_Boundeds Unbounded action => main::group
\&  Top            ::= Unbounded action => main::group
\&  Max_Boundeds   ::= Max_Bounded+
\&  Max_Bounded    ::= Eq_Finals Var_Final
\&  Max_Bounded    ::= Var_Final
\&  Unbounded      ::= Eq_Finals
\&  Eq_Finals      ::= Eq_Final+
\&  Eq_Final       ::= VAR \*(Aq=\*(Aq     action => main::concat
\&  Var_Final      ::= VAR         action => main::concat
\&  VAR ~ [\ew]+
.Ve
.SS "Abstract Syntax Forests (ASFs)"
.IX Subsection "Abstract Syntax Forests (ASFs)"
Ranking can also be implemented using Marpa's
abstract syntax forests.
ASFs are likely to be less efficient than the built in ranking,
but they are a more general and powerful solution.
.SH "Comparison with PEG"
.IX Header "Comparison with PEG"
For those familiar with \s-1PEG,\s0
Marpa's ranking may seem familiar.
In fact, Marpa's ranking can be seen as a \*(L"better \s-1PEG\*(R".\s0
.PP
A \s-1PEG\s0 specification looks like a \s-1BNF\s0 grammar.
It is a common misconception that a \s-1PEG\s0 specification implements
the same language that it would if interpreted as pure, unranked
\&\s-1BNF.\s0
This is the case only when the grammar is \s-1\fBLL\s0\fR\|(1) \*(--
in other words, rarely in practical use.
.PP
Typically, a \s-1PEG\s0 implementer thinks their problem out in \s-1BNF,\s0
perhaps ordering the \s-1PEG\s0 rules to resolve a few of the choices,
and then twiddles the \s-1PEG\s0 specification until the test suite passes.
This results in a parser whose behavior is to a large extent unknown.
.PP
Marpa with ranking allows a safer form of PEG-style parsing.
Both Marpa's \s-1DSL\s0 and \s-1PEG\s0 allow the implementer to specify
any context-free grammar,
but Marpa parses all context-free grammars correctly,
while \s-1PEG\s0 only correctly parses a small subset of the context-free grammars
and fakes the rest.
.PP
In Marpa,
the implementer of a ranked grammar can work systematically.
He can first write a \*(L"superset grammar\*(R",
and then \*(L"sculpt\*(R" it using ranks until he has exactly
the language he wants.
At all points, the superset grammar
will act as a \*(L"safety net\*(R".
That is,
ranking or no ranking,
Marpa returns no parse trees that are not specified by
the \s-1BNF\s0 grammar.
.PP
This \*(L"sculpted superset\*(R" is more likely to result in a
satisfactory solution than the \s-1PEG\s0 approach.
The \s-1PEG\s0 specification, re-interpreted as pure \s-1BNF,\s0
will usually only parse
a subset of what the implementer needs,
and the implementer must use ranks to \*(L"stretch\*(R" the
grammar to describe what he has in mind.
.PP
Ranking is not as predictable as specifying \s-1BNF.\s0
The \*(L"safety net\*(R" provided by Marpa's \*(L"sculpted superset\*(R"
guards against over-liberal parsing.
This is important:
over-liberal parsing can be a security loophole,
and bugs caused by over-liberal parsing have been
the topic of security advisories.
.PP
Determining the exact language parsed
by a ranked grammar
in \s-1PEG\s0 is extremely hard \*(--
a small specialist literature has looked at this subject.
Most implementers don't bother trying \*(--
when the test suite passes, they consider the \s-1PEG\s0
implementation complete.
.PP
Ranking's effect is more straightforward in Marpa.
Above, we showed very informally that the example
in our synopsis does what it claims to do \*(--
that the parses returned
are actually, and only, those desired.
A more formal
proof
is given below.
.PP
Since Marpa parses all context-free grammars,
and Marpa parses most unambiguous grammars in linear time,
Marpa often parses your language efficiently when it is implemented as pure \s-1BNF,\s0
without rule ranking.
As one example, the ranked grammar in the synopsis
can be reimplemented as pure unranked
\&\s-1BNF\s0.
Where it is possible to convert your ranked grammar to a pure \s-1BNF\s0 grammar,
that will usually be the best and safest choice.
.SH "Details"
.IX Header "Details"
This section contains additional explanations,
not essential to understanding
the rest of this document.
Often they are formal or mathematical.
While some people find these helpful, others find them distracting,
which is why
they are segregated here.
.SS "Earley parsing"
.IX Subsection "Earley parsing"
In this section we
assume that the reader is comfortable
reading and analyzing \s-1BNF.\s0
We will often use the basic theorem
of Earley parsing.
As a reminder,
the theorem states
that an instance of a dotted rule is present
in a parse,
if and
only if that instance is valid for the input so far.
More formally:
.PP
\&\fB(\s-1EARLEY\s0)\fR:
Let \f(CW\*(C`G\*(C'\fR be a grammar.
Let \f(CW\*(C`Syms\*(C'\fR be the set of symbols in \f(CW\*(C`G\*(C'\fR
and let exactly one of the symbols
in \f(CW\*(C`Syms\*(C'\fR be distinguished as the
\&\*(L"start symbol\*(R".
Call the \*(L"start symbol\*(R", \f(CW\*(C`<Start>\*(C'\fR.
.PP
Let \f(CW\*(C`Terms\*(C'\fR be a subset of \f(CW\*(C`Syms\*(C'\fR
called the \*(L"terminals\*(R" of \f(CW\*(C`G\*(C'\fR.
Let \f(CW\*(C`W\*(C'\fR be a string of symbols from \f(CW\*(C`Terms\*(C'\fR.
Let \f(CW\*(C`W[i]\*(C'\fR be the \f(CW\*(C`i\*(C'\fR'th terminal of \f(CW\*(C`W\*(C'\fR,
so that the first terminal of \f(CW\*(C`W\*(C'\fR is
\&\f(CW\*(C`W[1]\*(C'\fR.
.PP
Where \f(CW\*(C`alpha\*(C'\fR and \f(CW\*(C`beta\*(C'\fR are sequences
of symbols in \f(CW\*(C`Syms\*(C'\fR,
let \f(CW\*(C`alpha => beta\*(C'\fR mean that \f(CW\*(C`alpha\*(C'\fR
derives \f(CW\*(C`beta\*(C'\fR in grammar \f(CW\*(C`G\*(C'\fR
in zero or more steps.
.PP
In this theorem,
let
\&\f(CW\*(C`alpha\*(C'\fR, \f(CW\*(C`beta\*(C'\fR, \f(CW\*(C`gamma\*(C'\fR,
\&\f(CW\*(C`delta\*(C'\fR be sequences
of zero or more symbols in \f(CW\*(C`Syms\*(C'\fR.
.PP
Theorem:
These two statement sets
are equivalent:
.PP
Statement set 1 is true if and only if
we have all of the following:
.PP
1a.
\&\f(CW\*(C`eitem\*(C'\fR is an instance of a dotted
rule, which we will treat
as a triple:
\&\f(CW\*(C`dp, origin, current\*(C'\fR.
In the literature,
a triple of this form is also called
an \*(L"Earley item\*(R".
.PP
1b.
\&\f(CW\*(C`dp\*(C'\fR is the dotted
rule
\&\f(CW\*(C`<A> ::= beta . gamma>\*(C'\fR.
.PP
Statement set 2 is true if and only if
we have all of the following:
.PP
2a. \f(CW\*(C`alpha => W[1] ... W[origin]\*(C'\fR
.PP
2b. \f(CW\*(C`beta => W[origin+1] .. W[current]\*(C'\fR
.PP
2c. \f(CW\*(C`<Start> => alpha <A> delta\*(C'\fR
.PP
The proof is omitted.
It can be found in Jay Earley's thesis,
in his original paper,
and in Aho and Ullmann's 1972 textbook.
.SS "Proof of correctness"
.IX Subsection "Proof of correctness"
Let \f(CW\*(C`G\*(C'\fR be the grammar in the
Marpa \s-1DSL\s0
synopsis,
Let \f(CW\*(C`W\*(C'\fR be a string,
and let \f(CW\*(C`ps\-pure\*(C'\fR be the set of parses
allowed by \f(CW\*(C`G\*(C'\fR,
treated as if it was pure unranked \s-1BNF.\s0
Let \f(CW\*(C`ps\-ranked\*(C'\fR be the
set of parses
allowed by the \f(CW\*(C`G\*(C'\fR
after ranking is taken
into account.
.PP
We will say string \f(CW\*(C`W\*(C'\fR is valid
if and only if \f(CW\*(C`ps\-pure\*(C'\fR is non-empty.
We will say that a parse set is
\&\*(L"unambiguous\*(R" if and only if
it contains at most one parse.
.PP
In the
less formal discussion
above,
we took an intuitive approach to
the idea of \*(L"longest highest\*(R",
one which made the unstated assumption
that optimizing for \*(L"longest highest\*(R"
locally would also optimize globally.
Here we make our idea of \*(L"longest highest\*(R"
explicit and justify it.
.PP
What \*(L"longest highest\*(R" means locally is reasonably obvious \*(--
if \f(CW\*(C`item3\*(C'\fR has more lexemes than \f(CW\*(C`item1\*(C'\fR,
then \f(CW\*(C`item3\*(C'\fR is \*(L"longer\*(R" than \f(CW\*(C`item1\*(C'\fR.
It is less clear what it means globally.
Items might overlap,
so that optimizing locally might make
the parse as a whole suboptimal.
.PP
We will define a \*(L"longest highest\*(R" parse of \f(CW\*(C`W\*(C'\fR as
one of the parses of \f(CW\*(C`W\*(C'\fR with the fewest \*(L"items\*(R".
This is based on the observations
that \f(CW\*(C`W\*(C'\fR is fixed in length;
and that,
if items are longer,
fewer of them will fit into \f(CW\*(C`W\*(C'\fR.
.PP
More formally,
let \f(CW\*(C`p\*(C'\fR be a parse,
and let \f(CW\*(C`ps\*(C'\fR be a parse set.
Let \f(CWItems(p)\fR be
the number of items in \f(CW\*(C`p\*(C'\fR.
Let \f(CW\*(C`Items(ps)\*(C'\fR,
be the minimum number of items of any parse in \f(CW\*(C`ps\*(C'\fR.
Then, if \f(CW\*(C`lh\*(C'\fR is a parse in \f(CW\*(C`ps\*(C'\fR and if,
for every parse \f(CW\*(C`p\*(C'\fR in parse set \f(CW\*(C`ps\*(C'\fR,
\&\f(CW\*(C`Items(lh) <= Items(p)\*(C'\fR,
we say that \f(CW\*(C`lh\*(C'\fR is a \*(L"longest highest\*(R" parse.
.PP
To conveniently represent token strings
we will represent them as literal strings
where
"\f(CW\*(C`v\*(C'\fR" stands for a \f(CW\*(C`<VAR>\*(C'\fR lexemes
and equal signs represent themselves.
For example, we might represent the token
string
.PP
.Vb 1
\&    <VAR> = <VAR>
.Ve
.PP
as the string
.PP
.Vb 1
\&    v=v
.Ve
.PP
\&\fBTheorem\fR:
If \f(CW\*(C`W\*(C'\fR is a valid string,
\&\f(CW\*(C`ps\-ranked\*(C'\fR contains exactly one
parse,
and that parse is
the \*(L"longest highest\*(R" parse.
.PP
\&\fBProof\fR:
Recall that a Marpa \f(CW\*(C`high_rank_only\*(C'\fR parse
first parses according to the pure unranked \s-1BNF,\s0
and then prunes the parse using ranking.
.PP
\&\fBPart 1\fR:
We will first examine \f(CW\*(C`ps\-pure\*(C'\fR,
the parse set which results from the pure
\&\s-1BNF\s0 phase.
.PP
\&\fB(1) \*(L"Item\*(R"\fR:
An \*(L"item\*(R" will means an instance of
one of the symbols
\&\f(CW\*(C`Item1\*(C'\fR,
\&\f(CW\*(C`Item2\*(C'\fR or
\&\f(CW\*(C`Item3\*(C'\fR.
When we want to show a token string's division into
items, we will enclose them in parentheses.
For example "\f(CW\*(C`(v=)(v=)(v)\*(C'\fR\*(L" will indicate that
the token string is divided into 3 items; and
\&\*(R"\f(CW\*(C`(v=)(v=v)\*(C'\fR" will represent the same token string
divided into 2 items.
.PP
\&\fB(2) \*(L"Factoring\*(R"\fR:
Analyzing the grammar \f(CW\*(C`G\*(C'\fR,
we see that it is a sequence of items,
and that \f(CW\*(C`G\*(C'\fR is ambiguous for a string \f(CW\*(C`W\*(C'\fR
if and only if that string divides into items
in more than one way.
We will call a division of \f(CW\*(C`W\*(C'\fR into items
a \*(L"factoring\*(R".
.PP
\&\fB(3) \*(L"Independence\*(R"\fR:
Let \f(CW\*(C`seq1\*(C'\fR and \f(CW\*(C`seq2\*(C'\fR be two factorings
of \f(CW\*(C`W\*(C'\fR into items.
Let \f(CW\*(C`first\*(C'\fR and \f(CW\*(C`last\*(C'\fR be two lexeme locations
such that \f(CW\*(C`first <= last\*(C'\fR.
.PP
Let \f(CW\*(C`sub1\*(C'\fR be a subsequence of one or more
items of \f(CW\*(C`seq1\*(C'\fR
that starts at \f(CW\*(C`first\*(C'\fR and ends at \f(CW\*(C`last\*(C'\fR.
Similarly,
let \f(CW\*(C`sub2\*(C'\fR be a subsequence of one or more
items of \f(CW\*(C`seq2\*(C'\fR
that starts at \f(CW\*(C`first\*(C'\fR and ends at \f(CW\*(C`last\*(C'\fR.
Let \f(CW\*(C`seq3\*(C'\fR be
the result of replacing
\&\f(CW\*(C`sub1\*(C'\fR in \f(CW\*(C`seq1\*(C'\fR with
\&\f(CW\*(C`sub2\*(C'\fR.
Then,
because \f(CW\*(C`G\*(C'\fR is a context free grammar,
\&\f(CW\*(C`seq3\*(C'\fR is also a factoring of \f(CW\*(C`W\*(C'\fR.
.PP
As an example,
Let \f(CW\*(C`W\*(C'\fR be \f(CW\*(C`v=vv=v\*(C'\fR,
let \f(CW\*(C`seq1\*(C'\fR be \f(CW\*(C`(v=v)(v=v)\*(C'\fR and
let \f(CW\*(C`seq2\*(C'\fR be \f(CW\*(C`(v=)(v)(v=)(v)\*(C'\fR.
Let \f(CW\*(C`first\*(C'\fR be 4 and \f(CW\*(C`last\*(C'\fR be 6,
so that \f(CW\*(C`sub1\*(C'\fR is \f(CW\*(C`(v=v)\*(C'\fR
and \f(CW\*(C`sub2\*(C'\fR is \f(CW\*(C`(v=)(v)\*(C'\fR.
Then \f(CW\*(C`seq3\*(C'\fR is \f(CW\*(C`(v=v)(v=)(v)\*(C'\fR.
We claimed that \f(CW\*(C`seq3\*(C'\fR must be a factoring of \f(CW\*(C`W\*(C'\fR,
and we can see that our claim is correct.
.PP
\&\fB(4)\fR:
Recall the discussion of lexeme
fenceposts.
We will say that a lexeme fencepost \f(CW\*(C`fp\*(C'\fR
is a \*(L"factoring barrier\*(R"
if it is not properly contained in any item.
More formally,
let \f(CW\*(C`First(it1)\*(C'\fR be first lexeme location of
an item \f(CW\*(C`it1\*(C'\fR,
and let \f(CW\*(C`Last(it1)\*(C'\fR be last lexeme location of
\&\f(CW\*(C`it1\*(C'\fR.
Let \f(CW\*(C`i\*(C'\fR
be a lexeme fencepost \f(CW\*(C`i\*(C'\fR such that,
for every item \f(CW\*(C`it\*(C'\fR,
either \f(CW\*(C`i <= First(it)\*(C'\fR or
\&\f(CW\*(C`i > Last(it)\*(C'\fR.
Then lexeme fencepost \f(CW\*(C`i\*(C'\fR is a factoring barrier.
.PP
\&\fB(5)\fR:
Where \f(CW\*(C`|W|\*(C'\fR is the length of \f(CW\*(C`W\*(C'\fR,
we can see from (4)
that fencepost \f(CW\*(C`|W|\*(C'\fR
is a factoring barrier.
.PP
\&\fB(6)\fR:
Also from (4) we see that
lexeme fencepost 0 is a factoring barrier.
.PP
\&\fB(7)\fR:
Let a \*(L"subfactoring\*(R" be a sequence of
items bounded by factoring barriers.
.PP
\&\fB(8)\fR:
Let a \*(L"minimal subfactoring\*(R" be a subfactoring
which does not properly contain any
factoring barriers.
From (5) and (6) we can see that \f(CW\*(C`W\*(C'\fR
can be divided into
one or more minimal subfactorings.
.PP
\&\fB(9)\fR:
We can see from \f(CW\*(C`G\*(C'\fR
that two \f(CW\*(C`VAR\*(C'\fRs never occur
together in the same item.
This means that wherever we do find two
\&\f(CW\*(C`VAR\*(C'\fRs in a row,
the lexeme fencepost between them is
a factoring barrier.
.PP
\&\fB(10)\fR:
No item begins with an equal sign ("\f(CW\*(C`=\*(C'\fR").
Every item begins with a \f(CW\*(C`<VAR>\*(C'\fR
token.
.PP
\&\fB(11)\fR:
Every minimal subfactoring starts with
a \f(CW\*(C`<VAR>\*(C'\fR token.
This is because every subfactoring starts
with an item, and from (10).
.PP
\&\fB(12)\fR:
Every minimal subfactoring start with
a \f(CW\*(C`<VAR>\*(C'\fR token and
alternates
equal signs and \f(CW\*(C`<VAR>\*(C'\fR lexemes:
that is, it has the pattern
"\f(CW\*(C`v=v=v= ...\*(C'\fR".
This follows from (9) and (11).
.PP
\&\fB(13)\fR:
We will call a minimal subfactoring
\&\*(L"var-bounded\*(R" or simply \*(L"bounded\*(R"
if it starts and ends with a
\&\f(CW\*(C`<VAR>\*(C'\fR token.
By (12), this means that it
has the pattern
"\f(CW\*(C`v=v=v= ... v\*(C'\fR".
.PP
\&\fB(14)\fR:
We will call a minimal subfactoring
\&\*(L"var-unbounded\*(R" or simply \*(L"unbounded\*(R"
if it is not var-bounded.
By (12), this means that it
has the pattern
"\f(CW\*(C`v=v= ... v=\*(C'\fR".
.PP
\&\fB(15)\fR:
If a \f(CW\*(C`<Item1>\*(C'\fR or
\&\f(CW\*(C`<Item3>\*(C'\fR occurs in
a minimal subfactoring,
it is the last item in that subfactoring.
.PP
To show (15), assume for a reductio ad absurdam
there is a minimal subfactoring with a non-final
\&\f(CW\*(C`<Item1>\*(C'\fR or
\&\f(CW\*(C`<Item3>\*(C'\fR.
Call that subfactoring \f(CW\*(C`f\*(C'\fR,
and call that item, \f(CW\*(C`it1\*(C'\fR.
.PP
\&\fB(15a)\fR:
Both
\&\f(CW\*(C`<Item1>\*(C'\fR and
\&\f(CW\*(C`<Item3>\*(C'\fR
end with a
\&\f(CW\*(C`<VAR>\*(C'\fR token,
so that \f(CW\*(C`it1\*(C'\fR ends in a
\&\f(CW\*(C`<VAR>\*(C'\fR token.
.PP
\&\fB(15b)\fR:
Since \f(CW\*(C`it1\*(C'\fR, by assumption for the reductio,
is non-final, there is a next item.
Call the next item \f(CW\*(C`it2\*(C'\fR.
.PP
\&\fB(15c)\fR:
By (10),
all items start with
\&\f(CW\*(C`<VAR>\*(C'\fR lexemes,
so that \f(CW\*(C`it2\*(C'\fR starts with a
\&\f(CW\*(C`<VAR>\*(C'\fR token.
.PP
\&\fB(15d)\fR:
From (15a) and (15c),
we know that
\&\f(CW\*(C`it1\*(C'\fR ends with a
\&\f(CW\*(C`<VAR>\*(C'\fR token
and
\&\f(CW\*(C`it2\*(C'\fR starts with a
\&\f(CW\*(C`<VAR>\*(C'\fR token,
so that there are two
\&\f(CW\*(C`<VAR>\*(C'\fR lexemes
at the fencepost between \f(CW\*(C`it1\*(C'\fR
and \f(CW\*(C`it2\*(C'\fR.
.PP
\&\fB(15e)\fR:
From (9) and (15d),
there is a factoring barrier
at the fencepost between \f(CW\*(C`it1\*(C'\fR
and \f(CW\*(C`it2\*(C'\fR.
.PP
\&\fB(15f)\fR:
All items, including \f(CW\*(C`it1\*(C'\fR
and \f(CW\*(C`it2\*(C'\fR
and of non-zero length
so that, from (15e),
we know that the fencepost between \f(CW\*(C`it1\*(C'\fR
and \f(CW\*(C`it2\*(C'\fR
is properly
inside subfactoring \f(CW\*(C`f\*(C'\fR.
.PP
\&\fB(15g)\fR:
From (15f)
we see that there is a factoring barrier
properly inside \f(CW\*(C`f\*(C'\fR.
But \f(CW\*(C`f\*(C'\fR is assumed for the reductio
to be minimal and therefore cannot
properly contain a factoring barrier.
.PP
\&\fB(15h)\fR:
(15g) shows the reductio,
and allows us to conclude that,
if \f(CW\*(C`f\*(C'\fR contains an
\&\f(CW\*(C`<Item1>\*(C'\fR or
an \f(CW\*(C`<Item3>\*(C'\fR,
that item must be the final item.
This is what we needed to show for (15).
.PP
\&\fB(16)\fR:
By (3), every minimal subfactoring is independent \*(--
in other words, no ambiguity crosses factoring barriers.
So we narrow our consideration of ambiguities to two cases:
ambiguities in unbounded minimal subfactorings, and
ambiguities in bounded minimal subfactorings.
.PP
\&\fB(17)\fR:
Every unbounded minimal subfactoring is unambiguous.
To show (17), let \f(CW\*(C`u\*(C'\fR be an
unbounded minimal subfactoring.
It follows from the definition of unbounded minimal subfactoring
(14), that \f(CW\*(C`u\*(C'\fR
ends in an equal sign.
Both \f(CW\*(C`<Item1>\*(C'\fR and
\&\f(CW\*(C`<Item3>\*(C'\fR end in \f(CW\*(C`<VAR>\*(C'\fR lexemes,
so that no
\&\f(CW\*(C`<Item1>\*(C'\fR or
\&\f(CW\*(C`<Item3>\*(C'\fR can be the last item
in \f(CW\*(C`u\*(C'\fR.
Therefore, by (15),
there is no
\&\f(CW\*(C`<Item1>\*(C'\fR or
\&\f(CW\*(C`<Item3>\*(C'\fR item
in \f(CW\*(C`u\*(C'\fR.
This means that every item
in \f(CW\*(C`u\*(C'\fR
is an
\&\f(CW\*(C`<Item2>\*(C'\fR item.
This in turn means that \f(CW\*(C`u\*(C'\fR
is unambiguous,
which shows (17).
.PP
\&\fB(18)\fR:
Every bounded minimal subfactoring parses either
as a sequence of \f(CW\*(C`Item2\*(C'\fR's followed by
an \f(CW\*(C`Item1\*(C'\fR;
or as
as a sequence of \f(CW\*(C`Item2\*(C'\fR's followed by
an \f(CW\*(C`Item3\*(C'\fR.
This follows from (1), (13) and (15).
.PP
\&\fB(19)\fR:
From (16), (17) and (18) it follows that
every ambiguity between subfactorings is between
bounded subfactorings
whose divisions into items take the two forms
.PP
"\f(CW\*(C`(v=) ... (v=) (v)\*(C'\fR"
.PP
and
.PP
"\f(CW\*(C`(v=) ... (v=v)\*(C'\fR"
.PP
\&\fBPart 2\fR:
We have now shown how pure \s-1BNF\s0 parsing works for the
grammar in the synopsis.
We next show the consequences of ranking.
.PP
\&\fB(20)\fR:
A completed instance of \f(CW\*(C`List ::= Item1\*(C'\fR
can only be found at lexeme location 1.
We know this from \f(CW\*(C`G\*(C'\fR and (\s-1EARLEY\s0).
.PP
\&\fB(21)\fR:
A completed instance of \f(CW\*(C`List ::= List Item1\*(C'\fR
can only be found at lexeme location 2 or after.
We know this from \f(CW\*(C`G\*(C'\fR and (\s-1EARLEY\s0).
.PP
\&\fB(22)\fR
At most one dotted rule with \f(CW\*(C`Item1\*(C'\fR as its last item
appears in a cause at any choicepoint.
We know this because all choices of a choicepoint
must be completions with the same current location,
and from (20) and (21).
.PP
\&\fB(23)\fR:
A completed instance of \f(CW\*(C`List ::= Item3\*(C'\fR
can only be found at lexeme location 3.
We know this from \f(CW\*(C`G\*(C'\fR and (\s-1EARLEY\s0).
.PP
\&\fB(24)\fR:
A completed instance of \f(CW\*(C`List ::= List Item3\*(C'\fR
can only be found at lexeme location 4 or after.
We know this from \f(CW\*(C`G\*(C'\fR and (\s-1EARLEY\s0).
.PP
\&\fB(25)\fR
At most one dotted rule with \f(CW\*(C`Item3\*(C'\fR as its last item
appears in a cause at any choicepoint.
We know this because all choices of a choicepoint
must be completions with the same current location,
and from (23) and (24).
.PP
\&\fB(26)\fR:
Consider the ambiguity shown in
(19) and let \f(CW\*(C`current\*(C'\fR be the lexeme fencepost at its end.
An item also ends at \f(CW\*(C`current\*(C'\fR so from \f(CW\*(C`G\*(C'\fR and (\s-1EARLEY\s0),
we know that there is at least one dotted rule instance
whose predot symbol is \f(CW\*(C`List\*(C'\fR and whose current
location is \f(CW\*(C`current\*(C'\fR.
The choicepoint can
have one of these dotted rules:
.PP
.Vb 4
\&     Top ::= List .
\&     List ::= List . Item3
\&     List ::= List . Item2
\&     List ::= List . Item1
.Ve
.PP
with location 0 as its origin and
\&\f(CW\*(C`current\*(C'\fR as its current location.
There may be more than one choicepoint fulfilling these
criteria.
.PP
Of the choicepoints fulfilling the criteria,
we arbitrarily pick one.
We call this choicepoint \f(CW\*(C`result\*(C'\fR.
We will see as we proceed that,
while the choicepoints may have different dotted rules,
our choice of one of them for \f(CW\*(C`result\*(C'\fR makes no difference in
the ranking logic.
The only properties of the \f(CW\*(C`result\*(C'\fR
that we will use are
dot position,
predot symbol,
and current location.
These properties are the same
regardless of which choicepoint
we picked for \f(CW\*(C`result\*(C'\fR.
.PP
\&\fB(27)\fR:
Recall that the \*(L"middle location\*(R" of a choice
is always the origin of its cause.
From (26) we see that,
for every possible rule in \f(CW\*(C`result\*(C'\fR,
the predot symbol is the first symbol of the
dotted rule.
This means that the origin of the causes of
\&\f(CW\*(C`result\*(C'\fR
must be the same as the origin of \f(CW\*(C`result\*(C'\fR.
From (26) we also know that
the origin of \f(CW\*(C`result\*(C'\fR is always location 0.
Therefore the origin of every one of the causes of \f(CW\*(C`result\*(C'\fR
must be location 0.
Therefore every one of the causes of \f(CW\*(C`result\*(C'\fR
has the same middle location.
.PP
\&\fB(28)\fR:
From (26) and (27) we know that, if \f(CW\*(C`cuz\*(C'\fR is a cause
of \f(CW\*(C`result\*(C'\fR,
it has an origin at location 0;
its current location is \f(CW\*(C`current\*(C'\fR;
and its \s-1LHS\s0 is \f(CW\*(C`List\*(C'\fR.
\&\f(CW\*(C`cuz\*(C'\fR may be any one of
.PP
.Vb 6
\&     List ::= Item3 .
\&     List ::= Item2 .
\&     List ::= Item1 .
\&     List ::= List Item3 .
\&     List ::= List Item2 .
\&     List ::= List Item1 .
.Ve
.PP
\&\fB(29)\fR:
From (19) and (\s-1EARLEY\s0) we know that dotted rules
ending in \f(CW\*(C`Item2\*(C'\fR are not valid choices at location \f(CW\*(C`current\*(C'\fR.
.PP
\&\fB(30)\fR:
From (19), (22), (28) and (\s-1EARLEY\s0) we know
that exactly one of the following two dotted rules
is the cause of a parse choice for \f(CW\*(C`result\*(C'\fR:
.PP
.Vb 2
\&     List ::= Item1 .
\&     List ::= List Item1 .
.Ve
.PP
\&\fB(31)\fR:
From (19), (25), (28) and (\s-1EARLEY\s0) we know
that exactly one of the following two dotted rules
is the cause of a parse choice for \f(CW\*(C`result\*(C'\fR:
.PP
.Vb 2
\&     List ::= Item3 .
\&     List ::= List Item3 .
.Ve
.PP
\&\fB(32)\fR:
From (28), (29), (30) and (31) we know that we will
have exactly two choices for \f(CW\*(C`result\*(C'\fR;
that the final symbol of the cause in one will be
\&\f(CW\*(C`Item1\*(C'\fR; and
that the final symbol of the cause in the other will be
\&\f(CW\*(C`Item3\*(C'\fR.
From the grammar in the synopsis,
we know that the cause ending in \f(CW\*(C`Item1\*(C'\fR
will have rank 1;
and that the cause ending in \f(CW\*(C`Item3\*(C'\fR
will have rank 3.
From this we see, since the ranking method is
\&\f(CW\*(C`high_rank_only\*(C'\fR, that the choice whose final symbol
is \f(CW\*(C`Item3\*(C'\fR will be the only one kept in \f(CW\*(C`P\-ranked\*(C'\fR.
We further see from (19) that this choice will have
fewer items than the alternative.
.PP
\&\fB(33)\fR:
From (19) we know that there is at
most one ambiguity per minimal subfactoring.
From (16) we know that ambiguity resolutions
of a minimal subfactoring are independent
of the ambiguity resolutions
in other minimal subfactorings.
From (32) we know that every subfactoring
in \f(CW\*(C`P\-ranked\*(C'\fR has exactly one factoring,
and that that factoring
is the one with the fewest items.
Therefore, \f(CW\*(C`P\-ranked\*(C'\fR will contain exactly one parse,
and that that parse will be \*(L"longest highest\*(R".
.PP
\&\fB\s-1QED\s0\fR.
.SH "Copyright and License"
.IX Header "Copyright and License"
.Vb 5
\&  Copyright 2018 Jeffrey Kegler
\&  This file is part of Marpa::R2.  Marpa::R2 is free software: you can
\&  redistribute it and/or modify it under the terms of the GNU Lesser
\&  General Public License as published by the Free Software Foundation,
\&  either version 3 of the License, or (at your option) any later version.
\&
\&  Marpa::R2 is distributed in the hope that it will be useful,
\&  but WITHOUT ANY WARRANTY; without even the implied warranty of
\&  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
\&  Lesser General Public License for more details.
\&
\&  You should have received a copy of the GNU Lesser
\&  General Public License along with Marpa::R2.  If not, see
\&  http://www.gnu.org/licenses/.
.Ve
