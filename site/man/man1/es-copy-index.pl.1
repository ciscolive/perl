.\" Automatically generated by Pod::Man 4.14 (Pod::Simple 3.40)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\" ========================================================================
.\"
.IX Title "ES-COPY-INDEX 1"
.TH ES-COPY-INDEX 1 "2020-09-16" "perl v5.32.0" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
es\-copy\-index.pl \- Copy an index from one cluster to another
.SH "VERSION"
.IX Header "VERSION"
version 7.8
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
es\-copy\-access.pl [options] [query to select documents]
.PP
Options:
.PP
.Vb 10
\&    \-\-source            (Required) The source index name for the copy
\&    \-\-destination       Destination index name, assumes source
\&    \-\-from              (Required) A server in the cluster where the index lives
\&    \-\-to                A server in the cluster where the index will be copied to
\&    \-\-block             How many docs to process in one batch, default: 1,000
\&    \-\-mapping           JSON mapping to use instead of the source mapping
\&    \-\-settings          JSON index settings to use instead of those from the source
\&    \-\-append            Instead of creating the index, add the documents to the destination
\&    \-\-help              print help
\&    \-\-manual            print full manual
.Ve
.PP
From App::ElasticSearch::Utilities:
.PP
.Vb 10
\&    \-\-local         Use localhost as the elasticsearch host
\&    \-\-host          ElasticSearch host to connect to
\&    \-\-port          HTTP port for your cluster
\&    \-\-proto         Defaults to \*(Aqhttp\*(Aq, can also be \*(Aqhttps\*(Aq
\&    \-\-http\-username HTTP Basic Auth username
\&    \-\-http\-password HTTP Basic Auth password (if not specified, and \-\-http\-user is, you will be prompted)
\&    \-\-password\-exec Script to run to get the users password
\&    \-\-noop          Any operations other than GET are disabled, can be negated with \-\-no\-noop
\&    \-\-timeout       Timeout to ElasticSearch, default 30
\&    \-\-keep\-proxy    Do not remove any proxy settings from %ENV
\&    \-\-index         Index to run commands against
\&    \-\-base          For daily indexes, reference only those starting with "logstash"
\&                     (same as \-\-pattern logstash\-* or logstash\-DATE)
\&    \-\-datesep       Date separator, default \*(Aq.\*(Aq also (\-\-date\-separator)
\&    \-\-pattern       Use a pattern to operate on the indexes
\&    \-\-days          If using a pattern or base, how many days back to go, default: 1
.Ve
.PP
See also the \*(L"\s-1CONNECTION ARGUMENTS\*(R"\s0 and \*(L"\s-1INDEX SELECTION ARGUMENTS\*(R"\s0 sections from App::ElasticSearch::Utilities.
.PP
From CLI::Helpers:
.PP
.Vb 10
\&    \-\-data\-file         Path to a file to write lines tagged with \*(Aqdata => 1\*(Aq
\&    \-\-tags              A comma separated list of tags to display
\&    \-\-color             Boolean, enable/disable color, default use git settings
\&    \-\-verbose           Incremental, increase verbosity (Alias is \-v)
\&    \-\-debug             Show developer output
\&    \-\-debug\-class       Show debug messages originating from a specific package, default: main
\&    \-\-quiet             Show no output (for cron)
\&    \-\-syslog            Generate messages to syslog as well
\&    \-\-syslog\-facility   Default "local0"
\&    \-\-syslog\-tag        The program name, default is the script name
\&    \-\-syslog\-debug      Enable debug messages to syslog if in use, default false
\&    \-\-nopaste           Use App::Nopaste to paste output to configured paste service
\&    \-\-nopaste\-public    Defaults to false, specify to use public paste services
\&    \-\-nopaste\-service   Comma\-separated App::Nopaste service, defaults to Shadowcat
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
This script allows you to copy data from one index to another on the same cluster or
on a separate cluster.  It handles index creation, either directly copying the mapping
and settings from the source index or from mapping/settings \s-1JSON\s0 files.
.PP
This script could also be used to split up an index into smaller indexes for any number of reasons.
.PP
This uses the reindex \s-1API\s0 to copy data from one cluster to another
.SH "NAME"
es\-copy\-index.pl \- Copy an index from one cluster to another
.SH "OPTIONS"
.IX Header "OPTIONS"
.IP "\fBfrom\fR" 8
.IX Item "from"
\&\fB\s-1REQUIRED\s0\fR: hostname or \s-1IP\s0 of the source cluster
.IP "\fBto\fR" 8
.IX Item "to"
Hostname or \s-1IP\s0 of the destination cluster, defaults to the same host unless otherwise specified.
.IP "\fBsource\fR" 8
.IX Item "source"
\&\fB\s-1REQUIRED\s0\fR: name of the source index for the copy
.IP "\fBdestination\fR" 8
.IX Item "destination"
Optional: change the name of the index on the destination cluster
.IP "\fBblock\fR" 8
.IX Item "block"
Batch size of docs to process in one retrieval, default is 1,000
.IP "\fBmapping\fR" 8
.IX Item "mapping"
Path to a file containing \s-1JSON\s0 mapping to use on the destination index
instead of the mapping directly from the source index.
.IP "\fBsettings\fR" 8
.IX Item "settings"
Path to a file containing \s-1JSON\s0 settings to use on the destination index
instead of the settings directly from the source index.
.IP "\fBappend\fR" 8
.IX Item "append"
This mode skips the index mapping and settings configuration and just being indexing
documents from the source into the destination.
.IP "\fBhelp\fR" 8
.IX Item "help"
Print this message and exit
.IP "\fBmanual\fR" 8
.IX Item "manual"
Print detailed help with examples
.SH "EXAMPLES"
.IX Header "EXAMPLES"
.SS "Copy to different cluster"
.IX Subsection "Copy to different cluster"
.Vb 1
\&   es\-copy\-index.pl \-\-from localhost \-\-to remote.cluster.com \-\-source logstash\-2013.01.11
.Ve
.SS "Rename an existing index"
.IX Subsection "Rename an existing index"
.Vb 1
\&   es\-copy\-index.pl \-\-from localhost \-\-source logstash\-2013.01.11 \-\-destination logs\-2013.01.11
.Ve
.SS "Subset an existing index"
.IX Subsection "Subset an existing index"
.Vb 4
\&   es\-copy\-index.pl \-\-from localhost \e
\&        \-\-source logstash\-2013.01.11 \e
\&        \-\-destination secure\-2013.01.11 \e
\&        category:\*(Aq(authentication authorization)\*(Aq
.Ve
.SS "Changing settings and mappings"
.IX Subsection "Changing settings and mappings"
.Vb 5
\&   es\-copy\-index.pl \-\-from localhost \e
\&        \-\-source logstash\-2013.01.11 \e
\&        \-\-destination testing\-new\-settings\-old\-data\-2013.01.11 \e
\&        \-\-settings new_settings.json \e
\&        \-\-mappings new_mappings.json
.Ve
.SS "Building an Incident Index using append"
.IX Subsection "Building an Incident Index using append"
Let's say we were investigating an incident and wanted to have
an index that contained the data we were interested in.  We could use different
retention rules for incident indexes and we could arbitrarily add data to them based
on searches being performed on the source index.
.PP
Here's our initial query, a bad actor on our admin login page.
.PP
.Vb 4
\&   es\-copy\-index.pl \-\-from localhost \e
\&        \-\-source logstash\-2013.01.11 \e
\&        \-\-destination incident\-rt1234\-2013.01.11 \e
\&        src_ip:1.2.3.4 dst:admin.exmaple.com and file:\*(Aq\e/login.php\*(Aq
.Ve
.PP
Later on, we discover there was another actor:
.PP
.Vb 5
\&   es\-copy\-index.pl \-\-from localhost \e
\&        \-\-source logstash\-2013.01.11 \e
\&        \-\-destination incident\-rt1234\-2013.01.11 \e
\&        \-\-append \e
\&        src_ip:4.3.2.1 dst:admin.exmaple.com and file:\*(Aq\e/login.php\*(Aq
.Ve
.PP
The \fBincident\-rt1234\-2013.01.11\fR index will now hold all the data from both of those queries.
.SH "Query Syntax Extensions"
.IX Header "Query Syntax Extensions"
The search string is pre-analyzed before being sent to ElasticSearch.  The following plugins
work to manipulate the query string and provide richer, more complete syntax for \s-1CLI\s0 applications.
.SS "App::ElasticSearch::Utilities::QueryString::AutoEscape"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::AutoEscape"
Provide an '=' prefix to a query string parameter to promote that parameter to a \f(CW\*(C`term\*(C'\fR filter.
.PP
This allows for exact matches of a field without worrying about escaping Lucene special character filters.
.PP
E.g.:
.PP
.Vb 1
\&    user_agent:"Mozilla/5.0 (iPhone; CPU iPhone OS 12_1_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0 Mobile/15E148 Safari/604.1"
.Ve
.PP
Is evaluated into a weird query that doesn't do what you want.   However:
.PP
.Vb 1
\&    =user_agent:"Mozilla/5.0 (iPhone; CPU iPhone OS 12_1_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0 Mobile/15E148 Safari/604.1"
.Ve
.PP
Is translated into:
.PP
.Vb 1
\&    { term => { user_agent => "Mozilla/5.0 (iPhone; CPU iPhone OS 12_1_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0 Mobile/15E148 Safari/604.1" } }
.Ve
.PP
Which provides an exact match to the term in the query.
.SS "App::ElasticSearch::Utilities::QueryString::Barewords"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::Barewords"
The following barewords are transformed:
.PP
.Vb 3
\&    or => OR
\&    and => AND
\&    not => NOT
.Ve
.SS "App::ElasticSearch::Utilities::QueryString::IP"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::IP"
If a field is an \s-1IP\s0 address uses \s-1CIDR\s0 Notation, it's expanded to a range query.
.PP
.Vb 1
\&    src_ip:10.0/8 => src_ip:[10.0.0.0 TO 10.255.255.255]
.Ve
.SS "App::ElasticSearch::Utilities::QueryString::Ranges"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::Ranges"
This plugin translates some special comparison operators so you don't need to
remember them anymore.
.PP
Example:
.PP
.Vb 1
\&    price:<100
.Ve
.PP
Will translate into a:
.PP
.Vb 1
\&    { range: { price: { lt: 100 } } }
.Ve
.PP
And:
.PP
.Vb 1
\&    price:>50,<100
.Ve
.PP
Will translate to:
.PP
.Vb 1
\&    { range: { price: { gt: 50, lt: 100 } } }
.Ve
.PP
\fISupported Operators\fR
.IX Subsection "Supported Operators"
.PP
\&\fBgt\fR via >, \fBgte\fR via >=, \fBlt\fR via <, \fBlte\fR via <=
.SS "App::ElasticSearch::Utilities::QueryString::Underscored"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::Underscored"
This plugin translates some special underscore surrounded tokens into
the Elasticsearch Query \s-1DSL.\s0
.PP
Implemented:
.PP
\fI_prefix_\fR
.IX Subsection "_prefix_"
.PP
Example query string:
.PP
.Vb 1
\&    _prefix_:useragent:\*(AqGo \*(Aq
.Ve
.PP
Translates into:
.PP
.Vb 1
\&    { prefix => { useragent => \*(AqGo \*(Aq } }
.Ve
.SS "App::ElasticSearch::Utilities::QueryString::FileExpansion"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::FileExpansion"
If the match ends in .dat, .txt, .csv, or .json then we attempt to read a file with that name and \s-1OR\s0 the condition:
.PP
.Vb 5
\&    $ cat test.dat
\&    50  1.2.3.4
\&    40  1.2.3.5
\&    30  1.2.3.6
\&    20  1.2.3.7
.Ve
.PP
Or
.PP
.Vb 5
\&    $ cat test.csv
\&    50,1.2.3.4
\&    40,1.2.3.5
\&    30,1.2.3.6
\&    20,1.2.3.7
.Ve
.PP
Or
.PP
.Vb 5
\&    $ cat test.txt
\&    1.2.3.4
\&    1.2.3.5
\&    1.2.3.6
\&    1.2.3.7
.Ve
.PP
Or
.PP
.Vb 5
\&    $ cat test.json
\&    { "ip": "1.2.3.4" }
\&    { "ip": "1.2.3.5" }
\&    { "ip": "1.2.3.6" }
\&    { "ip": "1.2.3.7" }
.Ve
.PP
We can source that file:
.PP
.Vb 2
\&    src_ip:test.dat      => src_ip:(1.2.3.4 1.2.3.5 1.2.3.6 1.2.3.7)
\&    src_ip:test.json[ip] => src_ip:(1.2.3.4 1.2.3.5 1.2.3.6 1.2.3.7)
.Ve
.PP
This make it simple to use the \-\-data\-file output options and build queries
based off previous queries. For .txt and .dat file, the delimiter for columns
in the file must be either a tab or a null.  For files ending in
\&.csv, Text::CSV_XS is used to accurate parsing of the file format.  Files
ending in .json are considered to be newline-delimited \s-1JSON.\s0
.PP
You can also specify the column of the data file to use, the default being the last column or (\-1).  Columns are
\&\fBzero-based\fR indexing. This means the first column is index 0, second is 1, ..  The previous example can be rewritten
as:
.PP
.Vb 1
\&    src_ip:test.dat[1]
.Ve
.PP
or:
    src_ip:test.dat[\-1]
.PP
For newline delimited \s-1JSON\s0 files, you need to specify the key path you want to extract from the file.  If we have a
\&\s-1JSON\s0 source file with:
.PP
.Vb 3
\&    { "first": { "second": { "third": [ "bob", "alice" ] } } }
\&    { "first": { "second": { "third": "ginger" } } }
\&    { "first": { "second": { "nope":  "fred" } } }
.Ve
.PP
We could search using:
.PP
.Vb 1
\&    actor:test.json[first.second.third]
.Ve
.PP
Which would expand to:
.PP
.Vb 1
\&    { "terms": { "actor": [ "alice", "bob", "ginger" ] } }
.Ve
.PP
This option will iterate through the whole file and unique the elements of the list.  They will then be transformed into
an appropriate terms query <http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-terms-query.html>.
.SS "App::ElasticSearch::Utilities::QueryString::Nested"
.IX Subsection "App::ElasticSearch::Utilities::QueryString::Nested"
Implement the proposed nested query syntax early.  Example:
.PP
.Vb 1
\&    nested_path:"field:match AND string"
.Ve
.SH "AUTHOR"
.IX Header "AUTHOR"
Brad Lhotsky <brad@divisionbyzero.net>
.SH "COPYRIGHT AND LICENSE"
.IX Header "COPYRIGHT AND LICENSE"
This software is Copyright (c) 2020 by Brad Lhotsky.
.PP
This is free software, licensed under:
.PP
.Vb 1
\&  The (three\-clause) BSD License
.Ve
